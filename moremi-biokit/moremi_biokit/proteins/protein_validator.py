"""
Antibody Metrics Collector V3

This module implements a comprehensive metrics collection system for proteins based on 
the metrics breakdown document. This version focuses on collecting all metrics for validation
and reporting purposes, while also calculating weighted scores for ranking.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Any, Union
import pandas as pd
from enum import Enum
import os
import logging
from datetime import datetime
from moremi_biokit import pdb_fetcher
from moremi_biokit.connectors import rcsb
import random

from Bio.SeqUtils.ProtParam import ProteinAnalysis
import numpy as np

from .analysis_tools import (
    perform_blast, analyze_with_protparam, predict_stability, predict_aggregation,
    predict_glycosylation, predict_structure, predict_bcell_epitopes,
    predict_developability, predict_conservancy, predict_binding_affinity, predict_immunogenicity
)

class MetricCategory(Enum):
    """Categories of metrics based on the comprehensive breakdown"""
    BLAST = "BLAST"
    PROTPARAM = "ProtParam"
    IMMUNOGENICITY = "Immunogenicity"
    STABILITY = "Stability"
    AGGREGATION = "Aggregation"
    GLYCOSYLATION = "Glycosylation"
    BINDING_AFFINITY = "Binding Affinity"
    STRUCTURE = "Structure"
    EPITOPE = "Epitope"
    DEVELOPABILITY = "Developability"
    CONSERVANCY = "Conservancy"
    
    
@dataclass
class ProteinMetrics:
    """Container for all calculated metrics for an protein"""
    sequence: str
    antigen: str
    antigen_id: Optional[str]
    molecular_weight: float
    molecular_formula: str
    
    # Combined Categories
    blast: Dict[str, Any]
    protparam: Dict[str, Any]
    immunogenicity: Dict[str, Any]
    stability: Dict[str, Any]
    aggregation: Dict[str, Any]
    glycosylation: Dict[str, Any]
    binding_affinity: Dict[str, Any]
    structure: Dict[str, Any]
    epitope: Dict[str, Any]
    developability: Dict[str, Any]
    conservancy: Dict[str, Any]
    
    # These scores will be calculated by the ranker, not the validator
    weighted_scores: Dict[str, float] = field(default_factory=dict)
    total_score: float = 0.0
    
    # Additional antigen information
    antigen_pdb_chain_id: Optional[str] = None
    
    warnings: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        """Convert metrics to dictionary format"""
        return {
            'sequence': self.sequence,
            'antigen': self.antigen,
            'antigen_id': self.antigen_id,
            'antigen_pdb_chain_id': self.antigen_pdb_chain_id,
            'molecular_weight': self.molecular_weight,
            'molecular_formula': self.molecular_formula,
            'metrics': {
                'blast': self.blast,
                'protparam': self.protparam,
                'immunogenicity': self.immunogenicity,
                'stability': self.stability,
                'aggregation': self.aggregation,
                'glycosylation': self.glycosylation,
                'binding_affinity': self.binding_affinity,
                'structure': self.structure,
                'epitope': self.epitope,
                'developability': self.developability,
                'conservancy': self.conservancy
            },
            'weighted_scores': self.weighted_scores,
            'total_score': self.total_score,
            'warnings': self.warnings
        }

@dataclass
class ProcessingResult:
    """Container for protein processing results"""
    sequence: str
    metrics: Optional[ProteinMetrics]
    error: Optional[str] = None
    success: bool = True

    def __str__(self) -> str:
        if self.success:
            return f"Success: {self.sequence[:20]}..."
        return f"Failed: {self.sequence[:20]}... - Error: {self.error}"

class ProteinValidator:
    """
    Enhanced protein metrics collector that gathers comprehensive metrics
    and calculates weighted scores for ranking.
    """
    
    def __init__(self, 
                 pdb_files_path: Optional[str] = None, # Directory to store PDBs generated by predict_structure
                 target_antigen_sequence: Optional[str] = None,
                 target_antigen_pdb_file_path: Optional[str] = None, # Direct path to a local antigen PDB file
                 target_antigen_pdb_chain_id: Optional[str] = None, # e.g., "1XYZ_A" for download and seq fetch
                 antigen_pdb_download_path: Optional[str] = None, # Directory to store downloaded antigen PDBs
                 metrics_to_run: Optional[List[MetricCategory]] = None # Specify which metric categories to run
                 ):
        """Initialize validator with metric ranges and flexible antigen specification.
        
        Args:
            pdb_files_path (Optional[str]): Directory to store PDB files generated by
                the structure prediction tools (e.g., ESMFold).
            target_antigen_sequence (Optional[str]): Directly provided antigen amino acid sequence.
            target_antigen_pdb_file_path (Optional[str]): Path to a local PDB file for the antigen.
            target_antigen_pdb_chain_id (Optional[str]): Antigen identifier as 'PDBID_CHAIN' (e.g., "1XYZ_A").
                                                        The PDB file will be fetched, and sequence for the chain extracted.

                                                        Considered if other specific antigen params are not set.
            antigen_pdb_download_path (Optional[str]): Directory to store downloaded antigen PDB files.
                                                       If not provided, downloads might be attempted to a default
                                                       location or fail if `pdb_fetcher.fetch_pdb` requires an output_dir.
            metrics_to_run (Optional[List[MetricCategory]]): A list of MetricCategory enums to specify which
                                                             metric calculations should be performed. If None, all metrics are run.
        """
        self.pdb_files_path = pdb_files_path # For ESMFold generated PDBs
        self.antigen_pdb_download_path = antigen_pdb_download_path # For downloaded antigen PDBs
        self.metrics_to_run = metrics_to_run # Store the list of metrics to run

        # Initialize core antigen properties
        self.target_antigen_sequence: Optional[str] = target_antigen_sequence
        self.target_antigen_pdb_path: Optional[str] = None
        self.target_antigen_pdb_id: Optional[str] = None
        self.target_antigen_chain_id: Optional[str] = None

        pdb_id_to_materialize = None

        # 1. Prioritize direct PDB file path for antigen
        if target_antigen_pdb_file_path:
            if os.path.isfile(target_antigen_pdb_file_path):
                self.target_antigen_pdb_path = target_antigen_pdb_file_path
                pdb_file_basename = os.path.basename(target_antigen_pdb_file_path)
                self.target_antigen_pdb_id = pdb_file_basename.split('.')[0].lower()
                logging.info(f"Using provided local antigen PDB file: {self.target_antigen_pdb_path} (Infered ID: {self.target_antigen_pdb_id})")
                if self.target_antigen_sequence:
                    logging.info(f"Using provided target_antigen_sequence for PDB file {self.target_antigen_pdb_id}.")
                else:
                    logging.warning(f"Local antigen PDB file {self.target_antigen_pdb_path} provided, but no corresponding target_antigen_sequence. Sequence-dependent metrics might be affected if sequence is not derivable from chain ID.")
                
            else:
                logging.warning(f"Provided target_antigen_pdb_file_path '{target_antigen_pdb_file_path}' is not a valid file. Ignoring.")

        
        # NEW STEP: Check if we have only antigen sequence but no PDB structure
        elif self.target_antigen_sequence:
            logging.info(f"Only antigen sequence provided without PDB structure. Will predict structure for binding affinity.")
            self._predict_antigen_structure()

        # 2. If no local PDB path, check for PDBID_CHAIN for download/seq fetch
        elif target_antigen_pdb_chain_id:
            # TODO: GETTING PROTEIN SEQUENCE FROM PDB CHAIN ID - CURRENTLY WORKING A MICROSERVICE FOR THIS
            try:
                pdb_id_val, chain_id_val = target_antigen_pdb_chain_id.split('_', 1)
                self.target_antigen_pdb_id = pdb_id_val.lower()
                self.target_antigen_chain_id = chain_id_val.upper()
                pdb_id_to_materialize = self.target_antigen_pdb_id
                logging.info(f"Antigen specified by PDB_CHAIN_ID: {self.target_antigen_pdb_id}_{self.target_antigen_chain_id}")

                if self.target_antigen_sequence is None:
                    logging.info(f"Fetching antigen sequence for {self.target_antigen_pdb_id}_{self.target_antigen_chain_id}...")
                    seq_details = rcsb.get_pdb_chain_sequence_details(self.target_antigen_pdb_id, self.target_antigen_chain_id)
                    if seq_details and seq_details.get('sequence'):
                        self.target_antigen_sequence = seq_details['sequence']
                        logging.info(f"Successfully fetched antigen sequence (len: {len(self.target_antigen_sequence)}) for {self.target_antigen_pdb_id}_{self.target_antigen_chain_id}.")
                    else:
                        logging.warning(f"Could not fetch antigen sequence for {self.target_antigen_pdb_id}_{self.target_antigen_chain_id}.")
                else:
                    logging.info(f"Using provided target_antigen_sequence for {self.target_antigen_pdb_id}_{self.target_antigen_chain_id}.")
            except ValueError:
                logging.error(f"Invalid format for target_antigen_pdb_chain_id: '{target_antigen_pdb_chain_id}'. Expected 'PDBID_CHAIN'. Parameter ignored.")
        
   

        # 3. Materialize PDB file if an ID for materialization is set and no local path was directly given
        if pdb_id_to_materialize and not self.target_antigen_pdb_path:
            self._materialize_antigen_pdb_file(pdb_id_to_materialize)

        # 4. Fallback to random internal PDB if no antigen PDB ID/path determined yet
        if not self.target_antigen_pdb_id and not self.target_antigen_pdb_path:
            logging.info("No specific target antigen PDB provided by user, attempting to use a random internal PDB ID.")
            internal_pdb_ids = pdb_fetcher.list_internal_pdb_ids()
            if internal_pdb_ids:
                random_pdb_id = random.choice(internal_pdb_ids)
                self.target_antigen_pdb_id = random_pdb_id # Set the ID
                logging.info(f"Randomly selected internal PDB ID for antigen: {self.target_antigen_pdb_id}")
                self._materialize_antigen_pdb_file(self.target_antigen_pdb_id)
                # For random PDB, sequence is unknown unless fetched, but we don't have a chain.
                if not self.target_antigen_sequence:
                    logging.warning(f"Using random PDB {self.target_antigen_pdb_id} as antigen. Antigen sequence is unknown as no chain was specified.")
            else:
                logging.warning("No internal PDBs found for default target antigen selection, and no specific antigen provided by user.")
        
        # Final logging of antigen state
        log_msg_pdb_id = self.target_antigen_pdb_id if self.target_antigen_pdb_id else "Not set/inferred"
        log_msg_pdb_path = self.target_antigen_pdb_path if self.target_antigen_pdb_path else "Not set"
        log_msg_chain_id = self.target_antigen_chain_id if self.target_antigen_chain_id else "Not set"
        log_msg_seq_status = 'Provided/Fetched' if self.target_antigen_sequence else 'Unknown'
        
        logging.info(
            f"ProteinValidator antigen setup: PDB_ID='{log_msg_pdb_id}', PDB_Path='{log_msg_pdb_path}', "
            f"Chain_ID='{log_msg_chain_id}', Sequence_Status='{log_msg_seq_status}'"
        )

    def _predict_antigen_structure(self):
        """
        Predicts the structure of the antigen sequence using structure_predictor.
        This method is called when user provides only target_antigen_sequence but no PDB structure.
        Sets self.target_antigen_pdb_path if prediction is successful.
        """
        if not self.target_antigen_sequence:
            logging.warning("Cannot predict antigen structure: No antigen sequence provided")
            return
            
        logging.info(f"Predicting structure for antigen sequence (len: {len(self.target_antigen_sequence)})")
        
        # Determine the output directory for the predicted structure
        antigen_structure_dir = self.pdb_files_path
        if not antigen_structure_dir:
            if self.antigen_pdb_download_path:
                antigen_structure_dir = self.antigen_pdb_download_path
            else:
                antigen_structure_dir = os.path.join(os.getcwd(), "predicted_antigen_structures")
                os.makedirs(antigen_structure_dir, exist_ok=True)
        
        try:
            # Import structure_predictor and use it to predict the structure
            from .analysis_tools import structure_predictor
            
            result = structure_predictor.predict_structure(
                sequence=self.target_antigen_sequence,
                output_directory=antigen_structure_dir,
                output_pdb_filename_prefix="antigen_structure"
            )
            
            if result and result.get("pdb_file_path"):
                self.target_antigen_pdb_path = result["pdb_file_path"]
                self.target_antigen_pdb_id = "predicted_antigen"  # Set a default ID for the predicted structure
                logging.info(f"Successfully predicted antigen structure. PDB file: {self.target_antigen_pdb_path}")
            else:
                logging.warning(f"Failed to predict antigen structure")
        except Exception as e:
            logging.error(f"Error predicting antigen structure: {str(e)}")

    def _materialize_antigen_pdb_file(self, pdb_id_to_materialize: str):
        """
        Helper function to fetch/locate and set the PDB file path for a given antigen PDB ID.
        Uses pdb_fetcher.fetch_pdb for external fetching.
        The download location is determined by self.antigen_pdb_download_path.
        Sets self.target_antigen_pdb_path.
        """
        if not pdb_id_to_materialize:
            logging.warning("_materialize_antigen_pdb_file called with no PDB ID.")
            return

        logging.info(f"Attempting to materialize PDB file for antigen ID: {pdb_id_to_materialize} using pdb_fetcher.fetch_pdb")

        output_directory_for_antigen_pdb = self.antigen_pdb_download_path

        if not output_directory_for_antigen_pdb:
            logging.warning(
                f"antigen_pdb_download_path is not set in ProteinValidator. "
                f"PDB file for antigen ID '{pdb_id_to_materialize}' might not be downloaded if fetch_pdb requires an output_dir. "
                f"Attempting fetch without explicit output directory (may use internal cache or fail)."
            )
            # Attempt fetch without output_dir, relying on pdb_fetcher's internal logic or cache
            fetched_info = pdb_fetcher.fetch_pdb(
                target=pdb_id_to_materialize,
                input_type='identifier',
                use_internal_db=True, # Allow checking internal if no download path specified
                output_dir=None 
            )
            if fetched_info and fetched_info.get("status") == "success" and fetched_info.get("pdb_path"):
                self.target_antigen_pdb_path = fetched_info.get("pdb_path")
                logging.info(f"Using PDB path (potentially internal or pre-existing) for antigen '{pdb_id_to_materialize}': {self.target_antigen_pdb_path}")
            else:
                logging.warning(f"Could not obtain a PDB path for antigen ID '{pdb_id_to_materialize}' via fetch_pdb without an explicit antigen_pdb_download_path.")
            return

        try:
            os.makedirs(output_directory_for_antigen_pdb, exist_ok=True)
            logging.info(f"Ensured antigen PDB download path exists: {output_directory_for_antigen_pdb}")

            fetched_info = pdb_fetcher.fetch_pdb(
                target=pdb_id_to_materialize,
                input_type='identifier',
                source_db='rcsb', 
                use_internal_db=False, # Prioritize external fetch when download path is given
                output_dir=output_directory_for_antigen_pdb,
                db_file_format='pdb'
            )

            if fetched_info and fetched_info.get("status") == "success" and fetched_info.get("pdb_path"):
                self.target_antigen_pdb_path = fetched_info.get("pdb_path")
                logging.info(f"Successfully fetched/materialized PDB for antigen '{pdb_id_to_materialize}' to '{self.target_antigen_pdb_path}' using pdb_fetcher.fetch_pdb.")
            else:
                status_msg = fetched_info.get('status', 'unknown') if fetched_info else 'fetch_pdb call failed'
                error_msg = fetched_info.get('message', 'No specific error message.') if fetched_info else ''
                logging.warning(
                    f"Could not fetch/materialize PDB for antigen ID '{pdb_id_to_materialize}' using pdb_fetcher.fetch_pdb "
                    f"to '{output_directory_for_antigen_pdb}'. Status: {status_msg}. Message: {error_msg}"
                )
        except Exception as e:
            logging.error(f"Exception during PDB materialization for '{pdb_id_to_materialize}' to '{output_directory_for_antigen_pdb}': {e}")

    def process_protein(self, sequence: str) -> ProcessingResult:
        """Process a single protein sequence and calculate all metrics"""
        protein_metrics = None
        try:
            # Basic sequence validation
            if not sequence or len(sequence) < 10:
                logging.warning(f"Invalid sequence: sequence is too short or empty")
                return ProcessingResult(
                    sequence=sequence,
                    metrics=None,
                    success=False,
                    error="Invalid sequence: sequence is too short or empty"
                )
            
            # Calculate basic properties
            analyzed_seq = ProteinAnalysis(sequence)
            molecular_weight = analyzed_seq.molecular_weight()
            molecular_formula = f"C{len(sequence)}H{len(sequence)*2}N{len(sequence)}O{len(sequence)}"
            
            # Collect all metrics
            metrics = {}
            
            # Initialize metrics container early so we can add warnings
            protein_metrics = ProteinMetrics(
                sequence=sequence,
                antigen=self.target_antigen_sequence or "",
                antigen_id=self.target_antigen_pdb_id or "Unknown",
                molecular_weight=molecular_weight,
                molecular_formula=molecular_formula,
                blast={},
                protparam={},
                immunogenicity={},
                stability={},
                aggregation={},
                glycosylation={},
                binding_affinity={},
                structure={},
                epitope={},
                developability={},
                conservancy={},
                warnings=[]
            )
            
            # Set antigen_pdb_chain_id if available
            if self.target_antigen_pdb_id and self.target_antigen_chain_id:
                protein_metrics.antigen_pdb_chain_id = f"{self.target_antigen_pdb_id}_{self.target_antigen_chain_id}"
            elif self.target_antigen_pdb_id == "predicted_antigen" and self.target_antigen_pdb_path:
                # This is a predicted structure
                protein_metrics.antigen_pdb_chain_id = "predicted_structure"
            
            # Print tree-style validation process header
            print(f"\n🧪 Processing protein sequence: {sequence[:20]}...")
            print(f"├── Calculating basic properties...")
            
            # BLAST analysis
            if self.metrics_to_run is None or MetricCategory.BLAST in self.metrics_to_run:
                logging.info(f"├── 🧬 Running BLAST analysis....")
                print("├── 🧬 Running BLAST analysis...")
                try:
                    blast_result = perform_blast(sequence)
                    metrics['blast'] = blast_result.get('blast_result', {})
                    protein_metrics.blast = metrics['blast']
                    logging.info(f"│   └── ✓ BLAST complete")
                    print("│   └── ✓ BLAST complete")
                except Exception as e:
                    error_msg = f"BLAST analysis failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.BLAST.value, error_msg)
                    metrics['blast'] = {"error": error_msg}
                    protein_metrics.blast = metrics['blast']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🧬 BLAST analysis {skip_msg.lower()}")
                print(f"├── 🧬 BLAST analysis {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.BLAST.value, skip_msg)
                metrics['blast'] = {"status": skip_msg}
                protein_metrics.blast = metrics['blast']
            
            # ProtParam analysis
            if self.metrics_to_run is None or MetricCategory.PROTPARAM in self.metrics_to_run:
                logging.info(f"├── 🔍 Calculating ProtParam properties...")
                print("├── 🔍 Analyzing ProtParam properties...")
                try:
                    protparam_result = analyze_with_protparam(sequence)
                    metrics['protparam'] = protparam_result.get('protein_params', {})
                    protein_metrics.protparam = metrics['protparam']
                    logging.info(f"│   └── ✓ ProtParam complete")
                    print("│   └── ✓ ProtParam complete")
                except Exception as e:
                    error_msg = f"ProtParam analysis failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.PROTPARAM.value, error_msg)
                    metrics['protparam'] = {"error": error_msg}
                    protein_metrics.protparam = metrics['protparam']
                else:
                    skip_msg = "Skipped by user configuration."
                    logging.info(f"├── 🔍 ProtParam analysis {skip_msg.lower()}")
                    print(f"├── 🔍 ProtParam analysis {skip_msg}")
                    self._add_warning(protein_metrics, MetricCategory.PROTPARAM.value, skip_msg)
                    metrics['protparam'] = {"status": skip_msg}
                    protein_metrics.protparam = metrics['protparam']
            
            # Immunogenicity prediction
            if self.metrics_to_run is None or MetricCategory.IMMUNOGENICITY in self.metrics_to_run:
                logging.info(f"├── 🦠 Assessing immunogenicity...")
                print("├── 🦠 Assessing immunogenicity...")
                try:
                    immunogenicity_result = predict_immunogenicity(sequence)
                    metrics['immunogenicity'] = immunogenicity_result
                    protein_metrics.immunogenicity = metrics['immunogenicity']
                    logging.info(f"│   └── ✓ Immunogenicity assessment complete")
                    print("│   └── ✓ Immunogenicity assessment complete")
                except Exception as e:
                    error_msg = f"Immunogenicity prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.IMMUNOGENICITY.value, error_msg)
                    metrics['immunogenicity'] = {"error": error_msg}
                    protein_metrics.immunogenicity = metrics['immunogenicity']
                else:
                    skip_msg = "Skipped by user configuration."
                    logging.info(f"├── 🦠 Immunogenicity assessment {skip_msg.lower()}")
                    print(f"├── 🦠 Immunogenicity assessment {skip_msg}")
                    self._add_warning(protein_metrics, MetricCategory.IMMUNOGENICITY.value, skip_msg)
                    metrics['immunogenicity'] = {"status": skip_msg}
                    protein_metrics.immunogenicity = metrics['immunogenicity']
            
            # Stability prediction
            if self.metrics_to_run is None or MetricCategory.STABILITY in self.metrics_to_run:
                logging.info(f"├── 🔥 Evaluating stability...")
                print("├── 🔥 Evaluating stability...")
                try:
                    stability_result = predict_stability(sequence)
                    metrics['stability'] = stability_result.get('stability_result', {})
                    protein_metrics.stability = metrics['stability']
                    logging.info(f"│   └── ✓ Stability evaluation complete")
                    print("│   └── ✓ Stability evaluation complete")
                except Exception as e:
                    error_msg = f"Stability prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.STABILITY.value, error_msg)
                    metrics['stability'] = {"error": error_msg}
                    protein_metrics.stability = metrics['stability']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🔥 Stability evaluation {skip_msg.lower()}")
                print(f"├── 🔥 Stability evaluation {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.STABILITY.value, skip_msg)
                metrics['stability'] = {"status": skip_msg}
                protein_metrics.stability = metrics['stability']
            
            # Aggregation prediction
            if self.metrics_to_run is None or MetricCategory.AGGREGATION in self.metrics_to_run:
                logging.info(f"├── 🧱 Predicting aggregation propensity...")
                print("├── 🧱 Predicting aggregation propensity...")
                try:
                    aggregation_result = predict_aggregation(sequence)
                    metrics['aggregation'] = aggregation_result.get('aggregation_result', {})
                    protein_metrics.aggregation = metrics['aggregation']
                    logging.info(f"│   └── ✓ Aggregation prediction complete")
                    print("│   └── ✓ Aggregation prediction complete")
                except Exception as e:
                    error_msg = f"Aggregation prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.AGGREGATION.value, error_msg)
                    metrics['aggregation'] = {"error": error_msg}
                    protein_metrics.aggregation = metrics['aggregation']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🧱 Aggregation prediction {skip_msg.lower()}")
                print(f"├── 🧱 Aggregation prediction {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.AGGREGATION.value, skip_msg)
                metrics['aggregation'] = {"status": skip_msg}
                protein_metrics.aggregation = metrics['aggregation']
            
            # Glycosylation prediction
            if self.metrics_to_run is None or MetricCategory.GLYCOSYLATION in self.metrics_to_run:
                logging.info(f"├── 🍭  Identifying glycosylation sites...")
                print("├── 🍭 Identifying glycosylation sites...")
                try:
                    glycosylation_result = predict_glycosylation(sequence)
                    metrics['glycosylation'] = glycosylation_result
                    protein_metrics.glycosylation = metrics['glycosylation']
                    logging.info(f"│   └── ✓ Glycosylation sites identified")
                    print("│   └── ✓ Glycosylation sites identified")
                except Exception as e:
                    error_msg = f"Glycosylation prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.GLYCOSYLATION.value, error_msg)
                    metrics['glycosylation'] = {"error": error_msg}
                    protein_metrics.glycosylation = metrics['glycosylation']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🍭 Glycosylation sites identification {skip_msg.lower()}")
                print(f"├── 🍭 Glycosylation sites identification {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.GLYCOSYLATION.value, skip_msg)
                metrics['glycosylation'] = {"status": skip_msg}
                protein_metrics.glycosylation = metrics['glycosylation']
            
            # Structure prediction
            if self.metrics_to_run is None or MetricCategory.STRUCTURE in self.metrics_to_run:
                logging.info(f"├── 🧩 Generating structural model...")
                print("├── 🧩 Generating structural model...")
                try:
                    structure_result = predict_structure(sequence, output_pdb_filename_prefix=molecular_formula, output_directory=self.pdb_files_path)
                    metrics['structure'] = structure_result
                    protein_metrics.structure = metrics['structure']
                    logging.info(f"│   └── ✓ Structural model generated.")
                    print("│   └── ✓ Structural model generated")
                except Exception as e:
                    error_msg = f"Structure prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.STRUCTURE.value, error_msg)
                    metrics['structure'] = {"error": error_msg}
                    protein_metrics.structure = metrics['structure']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🧩 Structural model generation {skip_msg.lower()}")
                print(f"├── 🧩 Structural model generation {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.STRUCTURE.value, skip_msg)
                metrics['structure'] = {"status": skip_msg}
                protein_metrics.structure = metrics['structure']
            
            # Binding affinity prediction
            if self.metrics_to_run is None or MetricCategory.BINDING_AFFINITY in self.metrics_to_run:
                logging.info(f"├── 🔗 Calculating binding affinity...")
                print("├── 🔗 Calculating binding affinity...")
                if self.target_antigen_pdb_path and protein_metrics.structure.get("pdb_file_path"):
                    try:
                        binding_result = predict_binding_affinity(self.target_antigen_pdb_path, protein_metrics.structure["pdb_file_path"])
                        metrics['binding_affinity'] = binding_result
                        protein_metrics.binding_affinity = metrics['binding_affinity']
                        antigen_source = "predicted" if self.target_antigen_pdb_id == "predicted_antigen" else f"{self.target_antigen_pdb_id}"
                        logging.info(f"│   └── ✓ Binding affinity calculated against {antigen_source} antigen")
                        print(f"│   └── ✓ Binding affinity calculated against {antigen_source} antigen")
                    except Exception as e:
                        error_msg = f"Binding affinity calculation failed: {str(e)}"
                        logging.warning(f"│   └── ⚠️ {error_msg}")
                        print(f"│   └── ⚠️ {error_msg}")
                        self._add_warning(protein_metrics, MetricCategory.BINDING_AFFINITY.value, error_msg)
                        metrics['binding_affinity'] = {"error": error_msg}
                        protein_metrics.binding_affinity = metrics['binding_affinity']
                else:
                    missing_items = []
                    if not self.target_antigen_pdb_path:
                        missing_items.append("antigen PDB structure")
                    if not protein_metrics.structure.get("pdb_file_path"):
                         # Check if structure prediction itself was skipped
                        if isinstance(protein_metrics.structure, dict) and protein_metrics.structure.get("status") == "Skipped by user configuration.":
                            missing_items.append("protein PDB structure (skipped by user)")
                        else:
                            missing_items.append("protein PDB structure (prediction failed or not available)")
                    
                    missing_str = " and ".join(missing_items)
                    error_msg = f"Binding affinity calculation skipped: Missing {missing_str}"
                    metrics['binding_affinity'] = {"error": error_msg}
                    protein_metrics.binding_affinity = metrics['binding_affinity']
                    self._add_warning(protein_metrics, MetricCategory.BINDING_AFFINITY.value, error_msg)
                    
                    logging.warning(f"│   └── ⚠️ Skipping binding affinity: Ligand(Antibody) PDB path: {protein_metrics.structure.get('pdb_file_path', 'N/A')}, Receptor(Antigen) PDB path: {self.target_antigen_pdb_path}")
                    print(f"│   └── ⚠️ Skipping binding affinity calculation due to missing {missing_str}")
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🔗 Binding affinity calculation {skip_msg.lower()}")
                print(f"├── 🔗 Binding affinity calculation {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.BINDING_AFFINITY.value, skip_msg)
                metrics['binding_affinity'] = {"status": skip_msg}
                protein_metrics.binding_affinity = metrics['binding_affinity']

            # Epitope prediction
            if self.metrics_to_run is None or MetricCategory.EPITOPE in self.metrics_to_run:
                logging.info(f"├── 🎯 Predicting epitopes...")
                print("├── 🎯 Predicting epitope regions...")
                try:
                    epitope_result = predict_bcell_epitopes(sequence)
                    metrics['epitope'] = epitope_result
                    protein_metrics.epitope = metrics['epitope']
                    logging.info(f"│   └── ✓ Epitope prediction complete")
                    print("│   └── ✓ Epitope prediction complete")
                except Exception as e:
                    error_msg = f"Epitope prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.EPITOPE.value, error_msg)
                    metrics['epitope'] = {"error": error_msg}
                    protein_metrics.epitope = metrics['epitope']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🎯 Epitope prediction {skip_msg.lower()}")
                print(f"├── 🎯 Epitope prediction {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.EPITOPE.value, skip_msg)
                metrics['epitope'] = {"status": skip_msg}
                protein_metrics.epitope = metrics['epitope']
            
            # Conservancy prediction
            if self.metrics_to_run is None or MetricCategory.CONSERVANCY in self.metrics_to_run:
                logging.info(f"├── 🌐 Analyzing sequence conservancy...")
                print("├── 🌐 Analyzing sequence conservancy...")
                try:
                    # Check if epitope prediction was run and successful
                    epitopes_for_conservancy = []
                    if isinstance(protein_metrics.epitope, dict) and protein_metrics.epitope.get('list_of_epitopes'):
                        epitopes_for_conservancy = protein_metrics.epitope['list_of_epitopes']
                    elif isinstance(protein_metrics.epitope, dict) and protein_metrics.epitope.get("status") == "Skipped by user configuration.":
                        self._add_warning(protein_metrics, MetricCategory.CONSERVANCY.value, "Skipped: dependent epitope prediction was skipped by user.")
                        raise ValueError("Conservancy calculation skipped due to epitope prediction being skipped by user.")

                    conservancy_result = predict_conservancy(sequence, epitopes_for_conservancy, save_csv = False, )
                    metrics['conservancy'] = conservancy_result
                    protein_metrics.conservancy = metrics['conservancy']
                    logging.info(f"│   └── ✓ Conservancy analysis complete")
                    print("│   └── ✓ Conservancy analysis complete")
                except Exception as e:
                    error_msg = f"Conservancy prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.CONSERVANCY.value, error_msg)
                    metrics['conservancy'] = {"error": error_msg}
                    protein_metrics.conservancy = metrics['conservancy']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🌐 Conservancy analysis {skip_msg.lower()}")
                print(f"├── 🌐 Conservancy analysis {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.CONSERVANCY.value, skip_msg)
                metrics['conservancy'] = {"status": skip_msg}
                protein_metrics.conservancy = metrics['conservancy']
            
            # Developability prediction
            if self.metrics_to_run is None or MetricCategory.DEVELOPABILITY in self.metrics_to_run:
                logging.info(f"├── 🔧 Assessing developability...")
                print("├── 🔧 Assessing developability...")
                try:
                    developability_result = predict_developability(sequence)
                    metrics['developability'] = developability_result
                    protein_metrics.developability = metrics['developability']
                    logging.info(f"│   └── ✓ Developability assessment complete") # Added missing logging
                    print("│   └── ✓ Developability assessment complete")
                except Exception as e:
                    error_msg = f"Developability prediction failed: {str(e)}"
                    logging.warning(f"│   └── ⚠️ {error_msg}")
                    print(f"│   └── ⚠️ {error_msg}")
                    self._add_warning(protein_metrics, MetricCategory.DEVELOPABILITY.value, error_msg)
                    metrics['developability'] = {"error": error_msg}
                    protein_metrics.developability = metrics['developability']
            else:
                skip_msg = "Skipped by user configuration."
                logging.info(f"├── 🔧 Developability assessment {skip_msg.lower()}")
                print(f"├── 🔧 Developability assessment {skip_msg}")
                self._add_warning(protein_metrics, MetricCategory.DEVELOPABILITY.value, skip_msg)
                metrics['developability'] = {"status": skip_msg}
                protein_metrics.developability = metrics['developability']
            
            # Check how many metrics categories have errors and add warnings if needed
            error_categories = []
            for category, value in metrics.items():
                if isinstance(value, dict) and "error" in value:
                    error_categories.append(category)
            
            # Report if too many categories failed
            if error_categories:
                self._add_warning(protein_metrics, "General", 
                                f"Failed to calculate {len(error_categories)} metrics: {', '.join(error_categories)}")
                
                if len(error_categories) > len(MetricCategory) * 0.3:  # More than 30% failed
                    self._add_warning(protein_metrics, "Critical", 
                                    f"More than 30% of metric categories failed. Results may be unreliable.")
            
            logging.info(f"└── 📊 Collection of metrics complete...")
            print("└── 📊 Collection of metrics complete")
            
            # Summarize warnings
            if protein_metrics.warnings:
                warning_count = len(protein_metrics.warnings)
                logging.info(f"⚠️ Protein has {warning_count} warnings/issues")
                print(f"⚠️ Protein has {warning_count} warnings/issues")
            
            logging.info(f"✅ Successfully processed protein {sequence[:20]}...")
            print(f"✅ Successfully processed protein {sequence[:20]}...")
            
            return ProcessingResult(
                sequence=sequence,
                metrics=protein_metrics,
                success=True
            )
            
        except Exception as e:
            # Get full exception info for better debugging
            import traceback
            tb = traceback.format_exc()
            error_msg = f"Error during processing: {str(e)}"
            logging.error(f"❌ {error_msg}\n{tb}")
            print(f"❌ {error_msg}")
            
            return ProcessingResult(
                sequence=sequence,
                metrics=protein_metrics,  # Return any metrics we've collected so far
                success=False,
                error=error_msg
            )

    def process_proteins(self, input_file: str, output_dir: str = None) -> List[ProcessingResult]:
        """Process multiple protein sequences from a file (text or FASTA) and save results to output directory."""
        try:
            # Create results directory
            results_dir = output_dir or os.path.join(os.path.dirname(input_file), "results")
            os.makedirs(results_dir, exist_ok=True)
            
            sequences = []
            current_sequence_lines = []
            # Read all sequences from the input file
            with open(input_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#") or line.startswith("//"):
                        continue # Skip empty lines and comments
                    
                    if line.startswith(">"): # FASTA header
                        if current_sequence_lines: # Save previous sequence
                            sequences.append("".join(current_sequence_lines))
                            current_sequence_lines = []
                        # We can store or log the header if needed, for now, we just use it as a separator
                    else: # Sequence line
                        current_sequence_lines.append(line)
            
            if current_sequence_lines: # Add the last sequence in the file
                sequences.append("".join(current_sequence_lines))

            if not sequences:
                logging.warning(f"No valid sequences found in {input_file} (checked for plain and FASTA format)")
                return []
                
            logging.info(f"Found {len(sequences)} protein sequences in {input_file} (parsed as plain/FASTA format)")
            
            results = []
            success_count = 0
            error_count = 0
            
            # Process each protein
            logging.info(f"🌲 Starting batch processing of {len(sequences)} proteins...")
            print(f"\n🌲 Processing {len(sequences)} proteins from {input_file}")
            
            for i, sequence in enumerate(sequences):
                try:
                    logging.info(f"\nProcessing protein {i+1}/{len(sequences)}:")
                    result = self.process_protein(sequence)
                    results.append(result)
                    
                    if result.success:
                        success_count += 1
                        logging.info(f"✅ Successfully processed protein {i+1}")
                        print(f"│  ├── {i+1}/{len(sequences)}: ✅ Success")
                    else:
                        error_count += 1
                        logging.warning(f"❌ Failed to process protein {i+1}: {result.error}")
                        print(f"│  ├── {i+1}/{len(sequences)}: ❌ Error - {result.error}")
                
                except Exception as e:
                    error_count += 1
                    error_msg = f"Unexpected error: {str(e)}"
                    logging.error(f"❌ Exception processing protein {i+1}: {error_msg}")
                    print(f"│  ├── {i+1}/{len(sequences)}: ❌ Exception - {error_msg}")
                    # Create a failed result
                    results.append(ProcessingResult(
                        sequence=sequence,
                        metrics=None,
                        success=False,
                        error=error_msg
                    ))
            
            # Print summary tree
            print("│")
            print(f"└── 📊 Summary: {success_count} successful, {error_count} failed")
            
            for i, result in enumerate(results):
                status = "✅" if result.success else "❌"
                detail = f"Sequence: {result.sequence[:20]}..." if result.success else f"Error: {result.error}"
                print(f"    ├── {i+1}: {status} {detail}")
            
            logging.info(f"Completed processing {len(sequences)} proteins")
            logging.info(f"✅ Success: {success_count}, ❌ Failed: {error_count}")
            
            # Save results
            self.save_results(results, results_dir)
            logging.info(f"💾 Results saved to {results_dir}")
            
            return results
            
        except Exception as e:
            logging.error(f"❌ Error in batch processing: {str(e)}")
            import traceback
            logging.error(traceback.format_exc())
            
            # Return whatever results we've got so far, if any
            return results if 'results' in locals() else []
    
    # TODO: this so will be deleted after some confirmations
    def save_result(self, metrics: ProteinMetrics, output_dir: str):
        """Save individual protein metrics to a file"""
        
        # Convert metrics to dictionary and save
        metrics_dict = metrics.to_dict()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Correctly construct the directory path
        json_dir = os.path.join(output_dir, "json")

        # Create the directory if it doesn't exist
        os.makedirs(json_dir, exist_ok=True)

        output_file = os.path.join(json_dir, f"{metrics_dict['molecular_formula']}_{timestamp}.json")
        pd.DataFrame([metrics_dict]).to_json(output_file, orient='records', indent=2)
    
    # TODO: DELETE DO SOMETHING TO THIS GUY
    def save_summary(self, results: List[ProcessingResult], output_dir: str):
        """Save summary of all protein processing results"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_file = os.path.join(output_dir, f"protein_validation_summary_{timestamp}.txt")
        
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        with open(summary_file, 'w') as f:
            f.write("Protein Validation Summary\n")
            f.write("=========================\n\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("Overall Statistics:\n")
            f.write("-----------------\n")
            f.write(f"Total proteins processed: {len(results)}\n")
            f.write(f"Successfully processed: {len(successful)}\n")
            f.write(f"Failed: {len(failed)}\n\n")
            
            if successful:
                f.write("Successfully Processed Proteins:\n")
                f.write("--------------------------\n")
                for i, result in enumerate(successful[:10]):  # Show first 10 for brevity
                    f.write(f"{i+1}. Sequence: {result.sequence[:20]}...\n")
                    f.write(f"   Formula: {result.metrics.molecular_formula}\n")
                    f.write(f"   Weight: {result.metrics.molecular_weight:.2f}\n")
                    f.write("-" * 50 + "\n")
                
                if len(successful) > 10:
                    f.write(f"\n... and {len(successful) - 10} more proteins\n\n")
        
        if failed:
            f.write("\nFailed proteins:\n")
            f.write("-----------------\n")
            for result in failed:
                    f.write(f"Sequence: {result.sequence[:20]}...\n")
                    f.write(f"Error: {result.error}\n")
                    f.write("-" * 50 + "\n")

    def get_successful_metrics(self, results: List[ProcessingResult]) -> List[ProteinMetrics]:
        """Extract only successful metrics from processing results"""
        successful = []
        failed = []
        
        for i, result in enumerate(results):
            if result.success and result.metrics is not None:
                successful.append(result.metrics)
            else:
                error_msg = result.error if result.error else "Unknown error"
                seq_preview = result.sequence[:30] + "..." if result.sequence and len(result.sequence) > 30 else result.sequence
                failed.append((i, seq_preview, error_msg))
        
        # Log information about failed proteins
        if failed:
            logging.warning(f"❌ {len(failed)} proteins failed processing:")
            for i, seq, error in failed:
                logging.warning(f"  - Antibody #{i+1} (seq: {seq}): {error}")
        
        logging.info(f"✅ Successfully processed {len(successful)} out of {len(results)} proteins")
        return successful
    
    def validate_proteins(self, sequence_list: Union[str, List[str]]) -> List[ProteinMetrics]:
        """
        Validate a list of protein sequences or a single protein sequence string 
        by calling process_protein for each and returns a list of ProteinMetrics for successful validations.
        
        Args:
            sequence_list: A single protein sequence string or a list of protein sequences to validate.
            
        Returns:
            List of ProteinMetrics objects for valid proteins.
        """
        
        sequences_to_process: List[str]
        if isinstance(sequence_list, str):
            sequences_to_process = [sequence_list]
        elif isinstance(sequence_list, list):
            sequences_to_process = sequence_list
        else:
            logging.error("Invalid input type for sequence_list. Expected str or List[str].")
            print("Error: Invalid input for sequence_list. Must be a string or a list of strings.")
            return []

        print(f"\nStarting validation of {len(sequences_to_process)} proteins by leveraging process_protein...")
        valid_metrics_list = []
        invalid_count = 0
        
        for idx, sequence in enumerate(sequences_to_process, 1):
            print(f"\nValidating protein {idx}/{len(sequences_to_process)}: {sequence[:20]}...")
            result = self.process_protein(sequence) # Calls the main processing logic
            
            if result.success and result.metrics:
                valid_metrics_list.append(result.metrics)
                # process_protein already logs success, so we can keep this minimal
                print(f"└── Validation successful for protein {idx} (via process_protein)")
            else:
                invalid_count += 1
                # process_protein already logs failure
                print(f"└── Validation failed for protein {idx} (via process_protein). Error: {result.error}")
        
        print(f"\nValidation complete:")
        print(f"├── Total proteins attempted: {len(sequences_to_process)}")
        print(f"├── Successfully validated (metrics collected): {len(valid_metrics_list)}")
        print(f"└── Failed validation: {invalid_count}\n")
        
        return valid_metrics_list

    def get_metrics_as_dict_list(self, results: List[ProcessingResult]) -> List[Dict[str, Any]]:
        """
        Converts ProteinMetrics from a list of successful ProcessingResult objects into a list of dictionaries.

        Args:
            results: A list of ProcessingResult objects.

        Returns:
            A list of dictionaries, where each dictionary represents the metrics of a successfully processed protein.
        """
        dict_list = []
        for result in results:
            if result.success and result.metrics:
                try:
                    dict_list.append(result.metrics.to_dict())
                except Exception as e:
                    logging.error(f"Error converting metrics to dict for sequence {result.sequence[:20]}...: {e}")
        return dict_list

    def save_metrics_to_csv(self, results: List[ProcessingResult], output_csv_path: str):
        """
        Saves the ProteinMetrics from successful ProcessingResult objects to a CSV file.

        Args:
            results: A list of ProcessingResult objects.
            output_csv_path: The path (including filename) to save the CSV file.
        """
        if not results:
            logging.warning("No results provided to save_metrics_to_csv.")
            print("Warning: No results to save to CSV.")
            return

        metrics_dict_list = self.get_metrics_as_dict_list(results)
        
        if not metrics_dict_list:
            logging.warning("No successful metrics found to save to CSV.")
            print("Warning: No successful metrics to save to CSV.")
            return

        try:
            df = pd.DataFrame(metrics_dict_list)
            
            # Flatten nested dictionaries for better CSV representation if necessary
            # For example, if 'metrics' is a nested dict:
            if not df.empty and 'metrics' in df.columns:
                # This is a basic way to flatten; more sophisticated flattening might be needed
                # depending on the depth and structure of nested dicts.
                try:
                    metrics_expanded = pd.json_normalize(df['metrics'], sep='_')
                    df = df.drop(columns=['metrics'])
                    df = pd.concat([df, metrics_expanded], axis=1)
                except Exception as e:
                    logging.error(f"Could not fully flatten 'metrics' column for CSV: {e}. Proceeding with unflattened parts.")

            # Ensure output directory exists
            output_dir = os.path.dirname(output_csv_path)
            if output_dir: # If output_csv_path includes a directory
                os.makedirs(output_dir, exist_ok=True)
            
            df.to_csv(output_csv_path, index=False)
            logging.info(f"Successfully saved metrics for {len(metrics_dict_list)} proteins to CSV: {output_csv_path}")
            print(f"INFO: Metrics for {len(metrics_dict_list)} proteins saved to {output_csv_path}")
        except Exception as e:
            logging.error(f"Error saving metrics to CSV at {output_csv_path}: {e}")
            print(f"ERROR: Could not save metrics to CSV: {e}")

    def save_results(self, results: List[ProcessingResult], output_dir: str):
        """
        Save all results to the output directory, handling any errors gracefully.
        
        Args:
            results: List of processing results
            output_dir: Directory to save results
        """
        try:
            # Create output directory if it doesn't exist
            os.makedirs(output_dir, exist_ok=True)
            
            # Save summary first
            self.save_summary(results, output_dir)
            
            # Save individual successful results
            successful_count = 0
            for result in results:
                if result.success and result.metrics:
                    try:
                        self.save_result(result.metrics, output_dir)
                        successful_count += 1
                    except Exception as e:
                        logging.error(f"❌ Error saving result for {result.sequence[:20]}...: {str(e)}")
            
            logging.info(f"💾 Saved {successful_count} individual results to {output_dir}")
            
            # Save failed proteins to a separate file
            failed_results = [r for r in results if not r.success]
            if failed_results:
                failed_file = os.path.join(output_dir, "failed_proteins_details.json")
                with open(failed_file, 'w') as f:
                    import json
                    # Convert to serializable format
                    failed_data = [{
                        "sequence": r.sequence,
                        "error": r.error
                    } for r in failed_results]
                    json.dump(failed_data, f, indent=2)
                logging.info(f"❌ Saved {len(failed_results)} failed protein details to {failed_file}")
                
        except Exception as e:
            logging.error(f"❌ Error saving results: {str(e)}")
            import traceback
            logging.error(traceback.format_exc())

    def _add_warning(self, metrics: Optional[ProteinMetrics], category: str, message: str) -> None:
        """Add a warning to the metrics object if it exists"""
        if metrics and hasattr(metrics, 'warnings'):
            warning = f"{category}: {message}"
            metrics.warnings.append(warning)
            logging.warning(f"⚠️ {warning}")

if __name__ == "__main__":
    # Example usage
    # validator = ProteinValidator() # Original
    # Example with new parameters:
    # validator = ProteinValidator(pdb_files_path="validation_results/generated_pdbs", antigen_pdb_download_path="validation_results/downloaded_antigen_pdbs", target_antigen_pdb_chain_id="1XYZ_A")
    # validator = ProteinValidator(target_antigen_pdb_file_path="path/to/local/antigen.pdb", target_antigen_sequence="ANTIGENSEQUENCE")
    # validator = ProteinValidator(target_antigen_sequence="ANTIGENSEQUENCEONLY") # Might affect binding affinity if PDB path not derivable
    
    # Setup basic logging for testing
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

    # Test case 1: Using PDB_CHAIN_ID
    print("\n--- Test Case 1: PDB_CHAIN_ID ---")
    validator1 = ProteinValidator(
        pdb_files_path="validation_results/generated_pdbs_test1", 
        antigen_pdb_download_path="validation_results/downloaded_antigen_pdbs_test1",
        target_antigen_pdb_chain_id="4R19_A" # Example PDB and chain
    )
    if validator1.target_antigen_sequence:
        print(f"Antigen sequence fetched for 4R19_A: {validator1.target_antigen_sequence[:30]}...")
    if validator1.target_antigen_pdb_path:
        print(f"Antigen PDB path for 4R19_A: {validator1.target_antigen_pdb_path}")
    # results1 = validator1.process_proteins("proteins.txt", "validation_results/test1_output") # Assuming proteins.txt exists

    # Test case 2: Using local PDB file and sequence
    print("\n--- Test Case 2: Local PDB and Sequence ---")
    # Create a dummy antigen.pdb for testing this case
    dummy_pdb_dir = "validation_results/dummy_antigen_local" # This path is for the *local* antigen, not a download path
    os.makedirs(dummy_pdb_dir, exist_ok=True)
    dummy_pdb_path = os.path.join(dummy_pdb_dir, "6M0J.pdb") 
    if not os.path.exists(dummy_pdb_path):
         with open(dummy_pdb_path, "w") as f:
             f.write("HEADER    DUMMY PDB FILE FOR TESTING 6M0J\n")
             f.write("ATOM      1  N   MET A   1       0.000   0.000   0.000  1.00  0.00           N\n")
    
    validator2 = ProteinValidator(
        pdb_files_path="validation_results/generated_pdbs_test2", # Separate path for generated pdbs
        # antigen_pdb_download_path is not needed here as we provide a direct file path
        target_antigen_pdb_file_path=dummy_pdb_path,
        target_antigen_sequence="MTQVPSNPPPVVGARHNFSLKECGF" 
    )
    print(f"Antigen sequence (provided) for local PDB: {validator2.target_antigen_sequence[:30]}...")
    print(f"Antigen PDB path (local): {validator2.target_antigen_pdb_path}")
    print(f"Antigen PDB ID (inferred from local): {validator2.target_antigen_pdb_id}")
    # results2 = validator2.process_proteins("proteins.txt", "validation_results/test2_output")

    # Test case 3: Only antigen sequence
    print("\n--- Test Case 3: Antigen Sequence Only ---")
    validator3 = ProteinValidator(
        pdb_files_path="validation_results/generated_pdbs_test3",
        target_antigen_sequence="MTQVPSNPPPVVGARHNFSLKECGFKGRYSPTLASARERGYRAVDLLARHGITVSEAFRA"
    )
    print(f"Antigen sequence (provided): {validator3.target_antigen_sequence[:30]}...")
    print(f"Antigen PDB path: {validator3.target_antigen_pdb_path}") 
    print(f"Antigen PDB ID: {validator3.target_antigen_pdb_id}")
    # If structure prediction worked successfully, the PDB path should be set
    has_predicted_structure = validator3.target_antigen_pdb_path is not None
    print(f"Structure prediction successful: {has_predicted_structure}")
    # results3 = validator3.process_proteins("proteins.txt", "validation_results/test3_output")

    # Test case 4: Legacy PDB ID input
    print("\n--- Test Case 4: Legacy PDB ID Input ---")
    validator4 = ProteinValidator(
        pdb_files_path="validation_results/generated_pdbs_test4",
        antigen_pdb_download_path="validation_results/downloaded_antigen_pdbs_test4",
    )
    print(f"Antigen PDB ID (from legacy input): {validator4.target_antigen_pdb_id}")
    print(f"Antigen PDB path: {validator4.target_antigen_pdb_path}")
    print(f"Antigen sequence: {validator4.target_antigen_sequence}") # Expected to be None or user-provided
    # results4 = validator4.process_proteins("proteins.txt", "validation_results/test4_output")

    # Test case 5: Default (random internal PDB)
    print("\n--- Test Case 5: Default (Random Internal PDB) ---")
    # Assuming internal PDBs are set up for pdb_fetcher.list_internal_pdb_ids() to work
    # validator5 = ProteinValidator(
    #     pdb_files_path="validation_results/generated_pdbs_test5",
    #     antigen_pdb_download_path="validation_results/downloaded_antigen_pdbs_test5" # Path if it attempts download for random
    # )
    # print(f"Antigen PDB ID (random): {validator5.target_antigen_pdb_id}")

    # Test case 6: Specifying metrics to run
    print("\n--- Test Case 6: Specifying Metrics to Run ---")
    validator6 = ProteinValidator(
        pdb_files_path="validation_results/generated_pdbs_test6",
        antigen_pdb_download_path="validation_results/downloaded_antigen_pdbs_test6",
        target_antigen_pdb_chain_id="4R19_A", # Use a defined antigen for this test
        metrics_to_run=[
            MetricCategory.PROTPARAM,
            MetricCategory.STABILITY,
            MetricCategory.GLYCOSYLATION
        ]
    )
    print(f"Validator 6 initialized to run only: {[m.value for m in validator6.metrics_to_run]}")
    # Example of processing a single sequence with specified metrics:
    # dummy_sequence = "MTQVPSNPPPVVGARHNFSLKECGFKGRYSPTLASARERGYRAVDLLARHGITVSEAFRA"
    # result6 = validator6.process_protein(dummy_sequence)
    # if result6.success and result6.metrics:
    #     print(f"Metrics collected for {dummy_sequence[:10]}...: {list(result6.metrics.to_dict()['metrics'].keys())}")
    #     for category, details in result6.metrics.to_dict()['metrics'].items():
    #         if details.get("status") == "Skipped by user configuration.":
    #             print(f"  - {category} was skipped as expected.")
    #         elif "error" not in details:
    #             print(f"  + {category} was run.")
    #     print(f"Warnings: {result6.metrics.warnings}")


    pass # End of __main__ example updates
